{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install rdkit --pre deepchem"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zeL_lou2i3ct",
        "outputId": "313aba9d-cdea-4133-88ac-e341c6acc40e"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting rdkit\n",
            "  Downloading rdkit-2024.9.6-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.0 kB)\n",
            "Collecting deepchem\n",
            "  Downloading deepchem-2.8.1.dev20250418173725-py3-none-any.whl.metadata (2.0 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from rdkit) (2.0.2)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.11/dist-packages (from rdkit) (11.1.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from deepchem) (1.4.2)\n",
            "Collecting numpy (from rdkit)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m429.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from deepchem) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from deepchem) (1.6.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.11/dist-packages (from deepchem) (1.13.1)\n",
            "Requirement already satisfied: scipy>=1.10.1 in /usr/local/lib/python3.11/dist-packages (from deepchem) (1.14.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->deepchem) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->deepchem) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->deepchem) (2025.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->deepchem) (3.6.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy->deepchem) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->deepchem) (1.17.0)\n",
            "Downloading rdkit-2024.9.6-cp311-cp311-manylinux_2_28_x86_64.whl (34.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.3/34.3 MB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading deepchem-2.8.1.dev20250418173725-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m14.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m35.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy, rdkit, deepchem\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed deepchem-2.8.1.dev20250418173725 numpy-1.26.4 rdkit-2024.9.6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "DeepChem Model Optimization with PyTorch\n",
        "\n",
        "This script demonstrates how to optimize a DeepChem model using various PyTorch techniques:\n",
        "1. Using torch.compile for improved performance\n",
        "2. Analyzing the compilation process and Inductor backend\n",
        "3. Identifying bottlenecks in the training pipeline\n",
        "4. Applying optimization techniques like mixed precision, quantization, and knowledge distillation\n",
        "\"\"\"\n",
        "\n",
        "import deepchem as dc\n",
        "import numpy as np\n",
        "import torch\n",
        "import time\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.profiler import profile, record_function, ProfilerActivity\n",
        "import deepchem.models.losses as losses\n",
        "from deepchem.models.optimizers import Adam\n",
        "\n",
        "from torch.amp import autocast, GradScaler"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wFYnQ4uavwnU",
        "outputId": "bdf655cc-6dc8-47d1-ead4-fd733c2a38f6"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:deepchem.feat.molecule_featurizers.rdkit_descriptors:No normalization for SPS. Feature removed!\n",
            "WARNING:deepchem.feat.molecule_featurizers.rdkit_descriptors:No normalization for AvgIpc. Feature removed!\n",
            "WARNING:deepchem.feat.molecule_featurizers.rdkit_descriptors:No normalization for NumAmideBonds. Feature removed!\n",
            "WARNING:deepchem.feat.molecule_featurizers.rdkit_descriptors:No normalization for NumAtomStereoCenters. Feature removed!\n",
            "WARNING:deepchem.feat.molecule_featurizers.rdkit_descriptors:No normalization for NumBridgeheadAtoms. Feature removed!\n",
            "WARNING:deepchem.feat.molecule_featurizers.rdkit_descriptors:No normalization for NumHeterocycles. Feature removed!\n",
            "WARNING:deepchem.feat.molecule_featurizers.rdkit_descriptors:No normalization for NumSpiroAtoms. Feature removed!\n",
            "WARNING:deepchem.feat.molecule_featurizers.rdkit_descriptors:No normalization for NumUnspecifiedAtomStereoCenters. Feature removed!\n",
            "WARNING:deepchem.feat.molecule_featurizers.rdkit_descriptors:No normalization for Phi. Feature removed!\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.11/dist-packages/tensorflow/python/util/deprecation.py:588: calling function (from tensorflow.python.eager.polymorphic_function.polymorphic_function) with experimental_relax_shapes is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "experimental_relax_shapes is deprecated, use reduce_retracing instead\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n",
            "WARNING:deepchem.models.torch_models:Skipped loading modules with pytorch-geometric dependency, missing a dependency. No module named 'torch_geometric'\n",
            "WARNING:deepchem.models:Skipped loading modules with pytorch-geometric dependency, missing a dependency. cannot import name 'DMPNN' from 'deepchem.models.torch_models' (/usr/local/lib/python3.11/dist-packages/deepchem/models/torch_models/__init__.py)\n",
            "WARNING:deepchem.models:Skipped loading modules with pytorch-lightning dependency, missing a dependency. No module named 'lightning'\n",
            "WARNING:deepchem.models:Skipped loading some Jax models, missing a dependency. No module named 'haiku'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "wandb.init(project=\"prototype\",\n",
        "           config={\n",
        "               \"model\": \"MultitaskClassifier\",\n",
        "               \"optimizations\": [\"torch.compile\", \"quantization\", \"distillation\"],\n",
        "               \"dataset\": \"Tox21\"\n",
        "           })"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 319
        },
        "id": "tCceJA97NdAB",
        "outputId": "2355ad5e-b1e4-4590-db24-7c6cb67f8391"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msk5499\u001b[0m (\u001b[33mhpml-proj-deepchem\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.9"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250418_184322-xdcikujl</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/hpml-proj-deepchem/prototype/runs/xdcikujl' target=\"_blank\">fresh-planet-1</a></strong> to <a href='https://wandb.ai/hpml-proj-deepchem/prototype' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/hpml-proj-deepchem/prototype' target=\"_blank\">https://wandb.ai/hpml-proj-deepchem/prototype</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/hpml-proj-deepchem/prototype/runs/xdcikujl' target=\"_blank\">https://wandb.ai/hpml-proj-deepchem/prototype/runs/xdcikujl</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/hpml-proj-deepchem/prototype/runs/xdcikujl?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7d305f3084d0>"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set random seed for reproducibility\n",
        "np.random.seed(100)\n",
        "torch.manual_seed(100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ELUMN_hEvxk9",
        "outputId": "2cec7d7a-32e1-4d36-8eb0-a8d9a0c87ad7"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7d31daf468b0>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore', category=DeprecationWarning)\n"
      ],
      "metadata": {
        "id": "cTSv4_x7N-VY"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Load a dataset from DeepChem\n",
        "print(\"Loading Tox21 dataset...\")\n",
        "tox21_tasks, tox21_datasets, transformers = dc.molnet.load_tox21()\n",
        "train_dataset, valid_dataset, test_dataset = tox21_datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "4DgeCMbMvzPs",
        "outputId": "f3ccb418-f47e-4291-fb4f-95ab0c9ea10c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading Tox21 dataset...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Define a simple model architecture\n",
        "n_tasks = len(tox21_tasks)\n",
        "n_features = train_dataset.X.shape[1]\n",
        "print(f\"Dataset has {n_tasks} tasks and {n_features} features\")\n",
        "\n",
        "# Create a simple multilayer perceptron model\n",
        "model = dc.models.MultitaskClassifier(\n",
        "    n_tasks=n_tasks,\n",
        "    n_features=n_features,\n",
        "    layer_sizes=[1000, 500],\n",
        "    dropouts=[0.25, 0.25],\n",
        "    learning_rate=0.001\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EytjvweBv1Yc",
        "outputId": "4b7340cc-acbd-4190-83c2-cc9a5fb04cea"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset has 12 tasks and 1024 features\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 3: Baseline training and evaluation\n",
        "print(\"\\n--- Baseline Model Performance ---\")\n",
        "start_time = time.time()\n",
        "# Train for a small number of epochs for demonstration\n",
        "model.fit(train_dataset, nb_epoch=10)\n",
        "baseline_train_time = time.time() - start_time\n",
        "\n",
        "# Evaluate model\n",
        "baseline_scores = model.evaluate(test_dataset, metrics=[dc.metrics.Metric(dc.metrics.roc_auc_score)])\n",
        "print(f\"Baseline ROC-AUC: {baseline_scores['roc_auc_score']}\")\n",
        "print(f\"Baseline training time: {baseline_train_time:.2f} seconds\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oi-suuCEv358",
        "outputId": "4bed2df7-1c03-420d-fd29-ac71022ca3da"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Baseline Model Performance ---\n",
            "Baseline ROC-AUC: 0.6849960208233927\n",
            "Baseline training time: 2.62 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4: Apply torch.compile to the model\n",
        "print(\"\\n--- Applying torch.compile ---\")\n",
        "# Get the PyTorch model from the DeepChem wrapper\n",
        "torch_model = model.model\n",
        "\n",
        "# Create a compiled version of the model\n",
        "if hasattr(torch, 'compile'):  # Check if torch.compile is available (PyTorch 2.0+)\n",
        "    compiled_model = torch.compile(torch_model, backend=\"inductor\")\n",
        "    model.model = compiled_model\n",
        "\n",
        "    # Train with compiled model\n",
        "    start_time = time.time()\n",
        "    model.fit(train_dataset, nb_epoch=10)\n",
        "    compiled_train_time = time.time() - start_time\n",
        "\n",
        "    # Evaluate compiled model\n",
        "    compiled_scores = model.evaluate(test_dataset, metrics=[dc.metrics.Metric(dc.metrics.roc_auc_score)])\n",
        "    print(f\"Compiled model ROC-AUC: {compiled_scores['roc_auc_score']}\")\n",
        "    print(f\"Compiled model training time: {compiled_train_time:.2f} seconds\")\n",
        "    print(f\"Speedup: {baseline_train_time / compiled_train_time:.2f}x\")\n",
        "else:\n",
        "    print(\"torch.compile not available in this PyTorch version. Requires PyTorch 2.0+\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XnKdv8p5v8BP",
        "outputId": "637ad4d5-1791-4489-dbb7-5466c6c5537e"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Applying torch.compile ---\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "W0418 18:45:50.667000 655 torch/_inductor/utils.py:1137] [0/0] Not enough SMs to use max_autotune_gemm mode\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Compiled model ROC-AUC: 0.6691060087604739\n",
            "Compiled model training time: 17.07 seconds\n",
            "Speedup: 0.15x\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 5: Profile the model to identify bottlenecks\n",
        "print(\"\\n--- Profiling Model Performance ---\")\n",
        "\n",
        "def profile_model(model, dataset, name):\n",
        "    # Create a small batch for profiling\n",
        "    for X_batch, y_batch, w_batch, ids_batch in dataset.iterbatches(batch_size=32, pad_batches=True):\n",
        "         # Get the device the model is on\n",
        "        device = next(model.model.parameters()).device\n",
        "\n",
        "        # Move tensors to the same device as the model\n",
        "        X_tensor = torch.tensor(X_batch, dtype=torch.float32).to(device)\n",
        "        y_tensor = torch.tensor(y_batch, dtype=torch.float32).to(device)\n",
        "\n",
        "        # Profile forward pass\n",
        "        with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],\n",
        "                    record_shapes=True) as prof:\n",
        "            with record_function(f\"{name}_forward\"):\n",
        "                model.model(X_tensor)\n",
        "\n",
        "        print(f\"\\n{name} Forward Pass Profile:\")\n",
        "        print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))\n",
        "\n",
        "        # Profile backward pass if training\n",
        "        if model.model.training:\n",
        "            with profile(activities=[ProfilerActivity.CPU, ProfilerActivity.CUDA],\n",
        "                        record_shapes=True) as prof:\n",
        "                with record_function(f\"{name}_full_iteration\"):\n",
        "                    output = model.model(X_tensor)\n",
        "                    loss = model.loss_func(output, y_tensor)\n",
        "                    loss.backward()\n",
        "\n",
        "            print(f\"\\n{name} Full Training Iteration Profile:\")\n",
        "            print(prof.key_averages().table(sort_by=\"cpu_time_total\", row_limit=10))\n",
        "        break  # Only profile one batch\n",
        "\n",
        "# Profile the original model\n",
        "model.model = torch_model  # Restore the original model\n",
        "profile_model(model, train_dataset, \"Original\")\n",
        "\n",
        "# Profile the compiled model if available\n",
        "if hasattr(torch, 'compile'):\n",
        "    model.model = compiled_model\n",
        "    profile_model(model, train_dataset, \"Compiled\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0XCW8gn1v_Pu",
        "outputId": "9c9b169f-b5eb-4e79-cb4c-6d86bbf326a5"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Profiling Model Performance ---\n",
            "\n",
            "Original Forward Pass Profile:\n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                       Original_forward        32.48%       1.798ms        99.76%       5.523ms       5.523ms       0.000us         0.00%     127.966us     127.966us             1  \n",
            "                                           aten::linear         2.10%     115.985us        63.29%       3.503ms       1.168ms       0.000us         0.00%     122.814us      40.938us             3  \n",
            "                                            aten::addmm        40.82%       2.260ms        46.27%       2.561ms     853.756us      66.335us        92.79%     122.814us      40.938us             3  \n",
            "                                                aten::t        14.04%     777.459us        14.92%     826.032us     275.344us       0.000us         0.00%       0.000us       0.000us             3  \n",
            "          cudaOccupancyMaxActiveBlocksPerMultiprocessor         0.73%      40.205us         2.99%     165.509us      33.102us       0.000us         0.00%      56.479us      11.296us             5  \n",
            "                                       cudaLaunchKernel         2.76%     152.821us         2.76%     152.821us      16.980us       0.000us         0.00%       0.000us       0.000us             9  \n",
            "                                             aten::relu         0.82%      45.278us         2.60%     143.780us      71.890us       0.000us         0.00%       3.392us       1.696us             2  \n",
            "                                           Unrecognized         2.26%     125.304us         2.26%     125.304us      62.652us      56.479us        79.01%      56.479us      28.240us             2  \n",
            "                                        aten::clamp_min         1.22%      67.632us         1.78%      98.502us      49.251us       3.392us         4.74%       3.392us       1.696us             2  \n",
            "                                          aten::softmax         0.09%       4.888us         1.06%      58.815us      58.815us       0.000us         0.00%       1.760us       1.760us             1  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 5.536ms\n",
            "Self CUDA time total: 71.487us\n",
            "\n",
            "\n",
            "Compiled Forward Pass Profile:\n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                                   Name    Self CPU %      Self CPU   CPU total %     CPU total  CPU time avg     Self CUDA   Self CUDA %    CUDA total  CUDA time avg    # of Calls  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "                                       Compiled_forward         5.15%     181.448us        99.55%       3.504ms       3.504ms       0.000us         0.00%      99.613us      99.613us             1  \n",
            "                             Torch-Compiled Region: 0/2         6.26%     220.478us        92.87%       3.269ms       3.269ms       0.000us         0.00%      99.613us      99.613us             1  \n",
            "                                       CompiledFunction        72.45%       2.550ms        86.61%       3.049ms       3.049ms       0.000us         0.00%      99.613us      99.613us             1  \n",
            "                                               aten::mm         4.83%     170.170us         8.67%     305.130us     152.565us      62.110us        80.07%      84.157us      42.078us             2  \n",
            "                                            aten::addmm         1.63%      57.371us         2.44%      85.819us      85.819us      10.016us        12.91%      10.016us      10.016us             1  \n",
            "          cudaOccupancyMaxActiveBlocksPerMultiprocessor         0.50%      17.442us         2.38%      83.656us      27.885us       0.000us         0.00%      22.047us       7.349us             3  \n",
            "                                       cudaLaunchKernel         1.97%      69.525us         1.97%      69.525us      13.905us       0.000us         0.00%       0.000us       0.000us             5  \n",
            "                                           Unrecognized         1.88%      66.214us         1.88%      66.214us      66.214us      22.047us        28.42%      22.047us      22.047us             1  \n",
            "                               TorchDynamo Cache Lookup         1.52%      53.363us         1.52%      53.363us      53.363us       0.000us         0.00%       0.000us       0.000us             1  \n",
            "                          triton_poi_fused_addmm_relu_0         0.84%      29.475us         1.18%      41.400us      41.400us       2.080us         2.68%       2.080us       2.080us             1  \n",
            "-------------------------------------------------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  ------------  \n",
            "Self CPU time total: 3.520ms\n",
            "Self CUDA time total: 77.566us\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6: Apply mixed precision training\n",
        "print(\"\\n--- Mixed Precision Training ---\")\n",
        "if torch.cuda.is_available():\n",
        "    # Reset model\n",
        "    model = dc.models.MultitaskClassifier(\n",
        "        n_tasks=n_tasks,\n",
        "        n_features=n_features,\n",
        "        layer_sizes=[1000, 500],\n",
        "        dropouts=[0.25, 0.25],\n",
        "        learning_rate=0.001\n",
        "    )\n",
        "\n",
        "    # Move model to GPU\n",
        "    model.model = model.model.cuda()\n",
        "\n",
        "    # Apply mixed precision\n",
        "    from torch.amp import autocast, GradScaler\n",
        "\n",
        "    # Train with mixed precision\n",
        "    scaler = GradScaler('cuda')\n",
        "    start_time = time.time()\n",
        "\n",
        "    # Use BCEWithLogitsLoss since it's safe with autocast\n",
        "    loss_fn = torch.nn.BCEWithLogitsLoss()\n",
        "\n",
        "    # Get the PyTorch optimizer from the model\n",
        "    # Create a PyTorch optimizer for the model parameters\n",
        "    optimizer = torch.optim.Adam(model.model.parameters(), lr=0.001)\n",
        "\n",
        "    for epoch in range(10):\n",
        "        for X_batch, y_batch, w_batch, ids_batch in train_dataset.iterbatches(batch_size=32, pad_batches=True):\n",
        "            X_tensor = torch.tensor(X_batch, dtype=torch.float32).cuda()\n",
        "            y_tensor = torch.tensor(y_batch, dtype=torch.float32).cuda()\n",
        "\n",
        "            # Forward pass with autocast\n",
        "            with autocast('cuda'):\n",
        "                # Get raw logits from the model\n",
        "                output = model.model(X_tensor)\n",
        "                # The model returns a tuple, we need the logits\n",
        "                logits = output[0]\n",
        "\n",
        "                # For binary classification, we only need the logits for the positive class\n",
        "                # logits shape: [batch_size, num_tasks, 2] -> [batch_size, num_tasks]\n",
        "                logits = logits[:, :, 1]  # Take the logits for the positive class\n",
        "\n",
        "                # Reshape for BCEWithLogitsLoss\n",
        "                # logits shape: [batch_size, num_tasks] -> [batch_size * num_tasks]\n",
        "                # y_tensor shape: [batch_size, num_tasks] -> [batch_size * num_tasks]\n",
        "                batch_size, num_tasks = y_tensor.shape\n",
        "                logits = logits.view(-1)  # Flatten to 1D\n",
        "                y_tensor = y_tensor.view(-1)  # Flatten to 1D\n",
        "\n",
        "                # Calculate loss using BCEWithLogitsLoss\n",
        "                model_loss = loss_fn(logits, y_tensor)\n",
        "\n",
        "            # Backward pass with gradient scaling\n",
        "            optimizer.zero_grad()  # Use PyTorch's zero_grad\n",
        "            scaler.scale(model_loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "    mixed_precision_time = time.time() - start_time\n",
        "\n",
        "    # Evaluate model\n",
        "    mixed_precision_scores = model.evaluate(test_dataset, metrics=[dc.metrics.Metric(dc.metrics.roc_auc_score)])\n",
        "    print(f\"Mixed Precision ROC-AUC: {mixed_precision_scores['roc_auc_score']}\")\n",
        "    print(f\"Mixed Precision training time: {mixed_precision_time:.2f} seconds\")\n",
        "    print(f\"Speedup vs baseline: {baseline_train_time / mixed_precision_time:.2f}x\")\n",
        "else:\n",
        "    print(\"CUDA not available for mixed precision training\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X7E2kkkcwBxx",
        "outputId": "19bb636a-c141-4a31-a91f-27d480d72acc"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Mixed Precision Training ---\n",
            "Mixed Precision ROC-AUC: 0.5168608829116401\n",
            "Mixed Precision training time: 7.74 seconds\n",
            "Speedup vs baseline: 0.34x\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_model_size(model):\n",
        "    torch.save(model.state_dict(), \"temp_model.pt\")\n",
        "    size = os.path.getsize(\"temp_model.pt\") / (1024 * 1024)  # Size in MB\n",
        "    os.remove(\"temp_model.pt\")\n",
        "    return size"
      ],
      "metadata": {
        "id": "rohOR-n3Jz_9"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 7: Quantization\n",
        "print(\"\\n--- Model Quantization ---\")\n",
        "# Reset model\n",
        "model = dc.models.MultitaskClassifier(\n",
        "    n_tasks=n_tasks,\n",
        "    n_features=n_features,\n",
        "    layer_sizes=[1000, 500],\n",
        "    dropouts=[0.25, 0.25],\n",
        "    learning_rate=0.001\n",
        ")\n",
        "\n",
        "# Train on GPU\n",
        "if torch.cuda.is_available():\n",
        "    model.model = model.model.cuda()\n",
        "    print(\"Training on GPU...\")\n",
        "else:\n",
        "    print(\"CUDA not available. Exiting quantization...\")\n",
        "    exit()\n",
        "\n",
        "# Train the model\n",
        "start_time = time.time()\n",
        "model.fit(train_dataset, nb_epoch=10)\n",
        "training_time = time.time() - start_time\n",
        "print(f\"Training completed in {training_time:.2f} seconds\")\n",
        "\n",
        "# Convert model to FP16\n",
        "print(\"Converting model to FP16...\")\n",
        "model.model = model.model.half()  # Convert all parameters to float16\n",
        "\n",
        "# Create a new model for evaluation with the FP16 model\n",
        "quantized_eval_model = dc.models.MultitaskClassifier(\n",
        "    n_tasks=n_tasks,\n",
        "    n_features=n_features,\n",
        "    layer_sizes=[1000, 500],\n",
        "    dropouts=[0.25, 0.25],\n",
        "    learning_rate=0.001\n",
        ")\n",
        "\n",
        "# Set the FP16 model\n",
        "quantized_eval_model.model = model.model\n",
        "\n",
        "# Evaluate quantized model\n",
        "print(\"Evaluating quantized model...\")\n",
        "def evaluate_fp16(model, dataset):\n",
        "    model.model.eval()\n",
        "    all_predictions = []\n",
        "    all_targets = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X_batch, y_batch, w_batch, ids_batch in dataset.iterbatches(batch_size=32, pad_batches=True):\n",
        "            # Convert input to float16 and move to GPU\n",
        "            X_tensor = torch.tensor(X_batch, dtype=torch.float16).cuda()\n",
        "            y_tensor = torch.tensor(y_batch, dtype=torch.float32).cuda()\n",
        "\n",
        "            # Forward pass\n",
        "            predictions = model.model(X_tensor)\n",
        "            # Get the logits for the positive class (second column)\n",
        "            # predictions[0] shape: [batch_size, num_tasks, 2]\n",
        "            # We want the logits for the positive class (index 1)\n",
        "            positive_logits = predictions[0][:, :, 1]  # Shape: [batch_size, num_tasks]\n",
        "\n",
        "            # Convert to numpy and reshape for ROC-AUC\n",
        "            # Flatten the predictions and targets to match ROC-AUC requirements\n",
        "            batch_size, num_tasks = positive_logits.shape\n",
        "            positive_logits = positive_logits.view(-1).float().cpu().numpy()  # Flatten to 1D\n",
        "            y_tensor = y_tensor.view(-1).cpu().numpy()  # Flatten to 1D\n",
        "\n",
        "            all_predictions.append(positive_logits)\n",
        "            all_targets.append(y_tensor)\n",
        "\n",
        "    predictions = np.concatenate(all_predictions)\n",
        "    targets = np.concatenate(all_targets)\n",
        "    return dc.metrics.roc_auc_score(targets, predictions)\n",
        "\n",
        "# Evaluate using our FP16-aware function\n",
        "quantized_roc_auc = evaluate_fp16(quantized_eval_model, test_dataset)\n",
        "print(f\"Quantized model ROC-AUC: {quantized_roc_auc}\")\n",
        "\n",
        "# Compare model sizes\n",
        "def get_model_size(model):\n",
        "    torch.save(model.state_dict(), \"temp_model.pt\")\n",
        "    size = os.path.getsize(\"temp_model.pt\") / (1024 * 1024)  # Size in MB\n",
        "    os.remove(\"temp_model.pt\")\n",
        "    return size\n",
        "\n",
        "original_size = get_model_size(model.model)\n",
        "print(f\"Original model size: {original_size:.2f} MB\")\n",
        "# Note: FP16 model size is approximately half of original size\n",
        "print(f\"FP16 model size: ~{original_size/2:.2f} MB\")\n",
        "print(f\"Size reduction: ~50%\")\n",
        "\n",
        "# Compare inference times\n",
        "print(\"\\nComparing inference times...\")\n",
        "def measure_inference_time(model, dataset, name, num_batches=50):\n",
        "    model.model.eval()\n",
        "    batch_size = 32\n",
        "\n",
        "    # Determine input dtype based on model type\n",
        "    if name == \"Quantized Model\":\n",
        "        input_dtype = torch.float16\n",
        "        # Ensure model is in float16\n",
        "        model.model = model.model.half()\n",
        "    else:\n",
        "        input_dtype = torch.float32\n",
        "        # Ensure model is in float32\n",
        "        model.model = model.model.float()\n",
        "\n",
        "    # Warmup\n",
        "    for i, (X_batch, y_batch, w_batch, ids_batch) in enumerate(dataset.iterbatches(batch_size=batch_size, pad_batches=True)):\n",
        "        X_tensor = torch.tensor(X_batch, dtype=input_dtype).cuda()\n",
        "        with torch.no_grad():\n",
        "            _ = model.model(X_tensor)\n",
        "        if i >= 5:\n",
        "            break\n",
        "\n",
        "    # Measure inference time\n",
        "    start_time = time.time()\n",
        "    with torch.no_grad():\n",
        "        for i, (X_batch, y_batch, w_batch, ids_batch) in enumerate(dataset.iterbatches(batch_size=batch_size, pad_batches=True)):\n",
        "            X_tensor = torch.tensor(X_batch, dtype=input_dtype).cuda()\n",
        "            _ = model.model(X_tensor)\n",
        "            if i >= num_batches:\n",
        "                break\n",
        "\n",
        "    inference_time = (time.time() - start_time) / (num_batches + 1)\n",
        "    print(f\"{name} average inference time per batch: {inference_time*1000:.2f} ms\")\n",
        "    return inference_time\n",
        "\n",
        "# Compare original and quantized model inference times\n",
        "original_time = measure_inference_time(model, test_dataset, \"Original Model\")\n",
        "quantized_time = measure_inference_time(quantized_eval_model, test_dataset, \"Quantized Model\")\n",
        "print(f\"Speedup: {original_time/quantized_time:.2f}x faster\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6VqznmPXwHCl",
        "outputId": "29607dfe-8aea-4553-ffd3-ac0f8ac2636b"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Model Quantization ---\n",
            "Training on GPU...\n",
            "Training completed in 2.24 seconds\n",
            "Converting model to FP16...\n",
            "Evaluating quantized model...\n",
            "Quantized model ROC-AUC: 0.7179226128086514\n",
            "Original model size: 2.94 MB\n",
            "FP16 model size: ~1.47 MB\n",
            "Size reduction: ~50%\n",
            "\n",
            "Comparing inference times...\n",
            "Original Model average inference time per batch: 0.29 ms\n",
            "Quantized Model average inference time per batch: 0.27 ms\n",
            "Speedup: 1.06x faster\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.define_metric(\"epoch\")\n",
        "wandb.define_metric(\"loss\", step_metric=\"epoch\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZW0YdyUVORKj",
        "outputId": "1b9ecc23-5e31-4c05-b410-94e1f8cb3864"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<wandb.sdk.wandb_metric.Metric at 0x7d302badee50>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 8: Knowledge Distillation\n",
        "print(\"\\n--- Knowledge Distillation ---\")\n",
        "# Create a smaller student model\n",
        "student_model = dc.models.MultitaskClassifier(\n",
        "    n_tasks=n_tasks,\n",
        "    n_features=n_features,\n",
        "    layer_sizes=[500, 250],  # Smaller architecture\n",
        "    dropouts=[0.25, 0.25],\n",
        "    learning_rate=0.001\n",
        ")\n",
        "\n",
        "# Use the original model as teacher\n",
        "teacher_model = dc.models.MultitaskClassifier(\n",
        "    n_tasks=n_tasks,\n",
        "    n_features=n_features,\n",
        "    layer_sizes=[1000, 500],\n",
        "    dropouts=[0.25, 0.25],\n",
        "    learning_rate=0.001\n",
        ")\n",
        "teacher_model.model = torch_model  # Use the original non-quantized model\n",
        "\n",
        "# Move models to the same device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "teacher_model.model = teacher_model.model.to(device)\n",
        "student_model.model = student_model.model.to(device)\n",
        "\n",
        "# Implement knowledge distillation\n",
        "def distill(teacher, student, dataset, temperature=3.0, alpha=0.5, epochs=10):\n",
        "    student_model = student.model\n",
        "    teacher_model = teacher.model\n",
        "    teacher_model.eval()  # Teacher in eval mode\n",
        "\n",
        "    # KL divergence loss for soft targets\n",
        "    kl_criterion = torch.nn.KLDivLoss(reduction='batchmean')\n",
        "    # Hard target loss\n",
        "    ce_criterion = torch.nn.BCEWithLogitsLoss()\n",
        "\n",
        "    optimizer = torch.optim.Adam(student_model.parameters(), lr=0.001)\n",
        "\n",
        "    start_time = time.time()\n",
        "    for epoch in range(epochs):\n",
        "        total_loss = 0\n",
        "        batches = 0\n",
        "\n",
        "        for X_batch, y_batch, w_batch, ids_batch in dataset.iterbatches(batch_size=32, pad_batches=True):\n",
        "            # Move data to the same device as models\n",
        "            X_tensor = torch.tensor(X_batch, dtype=torch.float32).to(device)\n",
        "            y_tensor = torch.tensor(y_batch, dtype=torch.float32).to(device)\n",
        "\n",
        "            # Forward pass for teacher (no grad)\n",
        "            with torch.no_grad():\n",
        "                teacher_output = teacher_model(X_tensor)\n",
        "                # Get the logits from the tuple output\n",
        "                teacher_logits = teacher_output[0][:, :, 1]  # Take the positive class logits\n",
        "\n",
        "            # Forward pass for student\n",
        "            student_output = student_model(X_tensor)\n",
        "            # Get the logits from the tuple output\n",
        "            student_logits = student_output[0][:, :, 1]  # Take the positive class logits\n",
        "\n",
        "            # Reshape for loss calculation\n",
        "            batch_size, num_tasks = y_tensor.shape\n",
        "            teacher_logits = teacher_logits.view(-1)\n",
        "            student_logits = student_logits.view(-1)\n",
        "            y_tensor = y_tensor.view(-1)\n",
        "\n",
        "            # Compute soft targets with temperature\n",
        "            soft_targets = torch.sigmoid(teacher_logits / temperature)\n",
        "            soft_student = torch.sigmoid(student_logits / temperature)\n",
        "\n",
        "            # Distillation loss (soft targets)\n",
        "            distillation_loss = kl_criterion(\n",
        "                torch.log(soft_student + 1e-8),  # Add small epsilon to avoid log(0)\n",
        "                soft_targets\n",
        "            ) * (temperature ** 2)\n",
        "\n",
        "            # Student loss on hard targets\n",
        "            student_loss = ce_criterion(student_logits, y_tensor)\n",
        "\n",
        "            # Combined loss\n",
        "            loss = alpha * distillation_loss + (1 - alpha) * student_loss\n",
        "\n",
        "            wandb.log({\n",
        "                \"loss\": loss,\n",
        "                \"epoch\": epoch\n",
        "            })\n",
        "\n",
        "            # Backward and optimize\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "            batches += 1\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {total_loss/batches:.4f}\")\n",
        "\n",
        "    distill_time = time.time() - start_time\n",
        "    print(f\"Distillation completed in {distill_time:.2f} seconds\")\n",
        "\n",
        "# Perform distillation\n",
        "distill(teacher_model, student_model, train_dataset)\n",
        "\n",
        "# Evaluate student model\n",
        "student_scores = student_model.evaluate(test_dataset, metrics=[dc.metrics.Metric(dc.metrics.roc_auc_score)])\n",
        "print(f\"Student model ROC-AUC: {student_scores['roc_auc_score']}\")\n",
        "print(f\"Teacher model ROC-AUC: {baseline_scores['roc_auc_score']}\")\n",
        "\n",
        "# Compare model sizes\n",
        "student_size = get_model_size(student_model.model)\n",
        "print(f\"Teacher model size: {original_size:.2f} MB\")\n",
        "print(f\"Student model size: {student_size:.2f} MB\")\n",
        "print(f\"Size reduction: {(1 - student_size/original_size) * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TsD-2BE5wH21",
        "outputId": "616436ec-f1c5-46b3-b79d-f5deb1433847"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Knowledge Distillation ---\n",
            "Epoch 1/10, Loss: 0.3337\n",
            "Epoch 2/10, Loss: 0.3336\n",
            "Epoch 3/10, Loss: 0.3326\n",
            "Epoch 4/10, Loss: 0.3304\n",
            "Epoch 5/10, Loss: 0.3296\n",
            "Epoch 6/10, Loss: 0.3292\n",
            "Epoch 7/10, Loss: 0.3288\n",
            "Epoch 8/10, Loss: 0.3286\n",
            "Epoch 9/10, Loss: 0.3283\n",
            "Epoch 10/10, Loss: 0.3281\n",
            "Distillation completed in 8.39 seconds\n",
            "Student model ROC-AUC: 0.6610679193714081\n",
            "Teacher model ROC-AUC: 0.6849960208233927\n",
            "Teacher model size: 2.94 MB\n",
            "Student model size: 2.46 MB\n",
            "Size reduction: 16.24%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 9: Inference speed comparison\n",
        "print(\"\\n--- Inference Speed Comparison ---\")\n",
        "def measure_inference_time(model, dataset, name, num_batches=50):\n",
        "    model.model.eval()\n",
        "    batch_size = 32\n",
        "\n",
        "    # Determine input dtype based on model type\n",
        "    if name == \"Quantized Model\":\n",
        "        input_dtype = torch.float16\n",
        "        # Ensure model is in float16\n",
        "        model.model = model.model.half()\n",
        "    else:\n",
        "        input_dtype = torch.float32\n",
        "        # Ensure model is in float32\n",
        "        model.model = model.model.float()\n",
        "\n",
        "    # Warmup\n",
        "    for i, (X_batch, y_batch, w_batch, ids_batch) in enumerate(dataset.iterbatches(batch_size=batch_size, pad_batches=True)):\n",
        "        X_tensor = torch.tensor(X_batch, dtype=input_dtype).cuda()\n",
        "        with torch.no_grad():\n",
        "            _ = model.model(X_tensor)\n",
        "        if i >= 5:\n",
        "            break\n",
        "\n",
        "    # Measure inference time\n",
        "    start_time = time.time()\n",
        "    with torch.no_grad():\n",
        "        for i, (X_batch, y_batch, w_batch, ids_batch) in enumerate(dataset.iterbatches(batch_size=batch_size, pad_batches=True)):\n",
        "            X_tensor = torch.tensor(X_batch, dtype=input_dtype).cuda()\n",
        "            _ = model.model(X_tensor)\n",
        "            if i >= num_batches:\n",
        "                break\n",
        "\n",
        "    inference_time = (time.time() - start_time) / (num_batches + 1)\n",
        "    print(f\"{name} average inference time per batch: {inference_time*1000:.2f} ms\")\n",
        "    return inference_time\n",
        "\n",
        "# Compare inference times\n",
        "baseline_time = measure_inference_time(teacher_model, test_dataset, \"Original Model\")\n",
        "quantized_time = measure_inference_time(model, test_dataset, \"Quantized Model\")\n",
        "student_time = measure_inference_time(student_model, test_dataset, \"Distilled Student Model\")\n",
        "\n",
        "if hasattr(torch, 'compile'):\n",
        "    # Restore compiled model\n",
        "    teacher_model.model = compiled_model\n",
        "    compiled_time = measure_inference_time(teacher_model, test_dataset, \"Compiled Model\")\n",
        "\n",
        "    # Print speedup comparison\n",
        "    print(\"\\n--- Speedup Summary ---\")\n",
        "    print(f\"Compiled vs Original: {baseline_time/compiled_time:.2f}x faster\")\n",
        "    print(f\"Quantized vs Original: {baseline_time/quantized_time:.2f}x faster\")\n",
        "    print(f\"Student vs Original: {baseline_time/student_time:.2f}x faster\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BrEPAgpSwOH_",
        "outputId": "80a1a730-9c71-4163-9b2d-8602e08a4f28"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Inference Speed Comparison ---\n",
            "Original Model average inference time per batch: 0.32 ms\n",
            "Quantized Model average inference time per batch: 0.36 ms\n",
            "Distilled Student Model average inference time per batch: 0.51 ms\n",
            "Compiled Model average inference time per batch: 0.34 ms\n",
            "\n",
            "--- Speedup Summary ---\n",
            "Compiled vs Original: 0.95x faster\n",
            "Quantized vs Original: 0.88x faster\n",
            "Student vs Original: 0.63x faster\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 10: Visualization of results\n",
        "print(\"\\n--- Visualization ---\")\n",
        "# Plot inference times\n",
        "models = [\"Original\", \"Quantized\", \"Student\"]\n",
        "times = [baseline_time, quantized_time, student_time]\n",
        "\n",
        "if hasattr(torch, 'compile'):\n",
        "    models.append(\"Compiled\")\n",
        "    times.append(compiled_time)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(models, times)\n",
        "plt.title(\"Inference Time Comparison\")\n",
        "plt.ylabel(\"Time per batch (seconds)\")\n",
        "plt.savefig(\"inference_times.png\")\n",
        "print(\"Saved inference time comparison to 'inference_times.png'\")\n",
        "\n",
        "# Plot model sizes\n",
        "def get_model_size(model):\n",
        "    torch.save(model.state_dict(), \"temp_model.pt\")\n",
        "    size = os.path.getsize(\"temp_model.pt\") / (1024 * 1024)  # Size in MB\n",
        "    os.remove(\"temp_model.pt\")\n",
        "    return size\n",
        "\n",
        "# Calculate sizes for all models\n",
        "original_size = get_model_size(teacher_model.model)\n",
        "quantized_size = get_model_size(quantized_eval_model.model)\n",
        "student_size = get_model_size(student_model.model)\n",
        "\n",
        "sizes = [original_size, quantized_size, student_size]\n",
        "model_types = [\"Original\", \"Quantized\", \"Student\"]\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(model_types, sizes)\n",
        "plt.title(\"Model Size Comparison\")\n",
        "plt.ylabel(\"Size (MB)\")\n",
        "plt.savefig(\"model_sizes.png\")\n",
        "print(\"Saved model size comparison to 'model_sizes.png'\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "46BW1OMiwRLz",
        "outputId": "0aab4a3f-0b1a-47b2-a348-711c5c096d24"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Visualization ---\n",
            "Saved inference time comparison to 'inference_times.png'\n",
            "Saved model size comparison to 'model_sizes.png'\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "MKpjyDHri1IO"
      }
    }
  ]
}